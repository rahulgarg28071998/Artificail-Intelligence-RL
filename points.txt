about gym:

		env = gym.make('FrozenLake8x8-v0')
		Q = np.zeros([env.observation_space.n,env.action_space.n])
		#1. env.obeservation.n, env.action_space.n gives number of states and action in env loaded
		env.reset()
		for _ in range(500):
		     env.render()
		     env.step(env.action_space.sample())
		#2. To check all env available, uninstalled ones are also shown
		 from gym import envs 
		 print(envs.registry.all())


Q learning

Q[s,a] = Q[s,a] + eta*(r + gma*np.max(Q[s1,:]) - Q[s,a])
       
	   
	   
TensorBoard
	# Setup TensorBoard Writer
	#writer = tf.summary.FileWriter("/tensorboard/dqn/1")
	
	Update During Training
	 # writer.add_summary(summary, episode)
     # writer.flush()
	 
	from tensorflow.keras.callbacks import TensorBoard
	from time import time
	tensor = TensorBoard(log_dir="logs/{}".format(time()))
	  model.fit(X, y,epochs=30, 
                  shuffle=True,  
                  batch_size=32,
                  validation_split=0.20,
                    callbacks=[tensor])
	 
	 